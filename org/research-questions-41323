Research questions
	(1) How do you build a neural network (i.e., decide the architecture, including the number of layers, types of layers, and depths of layers)?
		Common approach
			Decide the architecture manually and code it manually.
		Proposed in this thesis
			Use an RL agent handle part of the architecture design.

	(2) How do you train a neural network?
		Common approach
			Train with SGD or other optimizer.
		Proposed in this thesis
			Use an RL agent alongside your optimizer. RL agent controls optimizer use: decides when to train (use optimizer), when to add new layer (no optimizer), when to add new layer and train (use optimizer).

	(3) How do you transfer learning from one network to another?
		Common approach
			Manually choose a neural network to fine tune for this problem domain and tune it.
		Proposed in this thesis
			Automatically choose a neural network to fine tune by incorporating past trained layers from other networks built and trained by the meta learning rl agent. Said another way, we reuse layers from past tasks because the RL agent will find these layers identifying them as advantageous to this new task.

	(4 - TODO) What training metadata can you introspect in a neural network? How can you use this data to improve performance?
		Maybe introspect can  be used to help inform 'how to learn' for RL tasks where an agent encounters an out of distribution state it wasn't trained for. It can expedite learning by using information on how it previously learned.


Past work
	2010 - Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design (https://icml.cc/Conferences/2010/papers/422.pdf)
		Treats optimization of function as mutliarm bandit problem. Uses gaussian process bandits


Related work
	2017 - Neural Architecture Search with Reinforcement Learning (https://arxiv.org/pdf/1611.01578.pdf)
		An RL agent is used to find the most performant hyperparameters for a neural network.
	2022 - Progressive Neural Networks (https://arxiv.org/pdf/1606.04671.pdf)
		Each subsequent task reuses all layers from prior networks (i.e., one network continues to grow across tasks) via a neural network adapter that decides how to integrate past layers' weights for this task.


Formulation
	Meta-learning
		Building a meta-learning operator f_o(f_i(f_params)), or a composite of learning operators. An inner loop f_i in F_i and an outer loop f_o in F_o. f_i is a model itself. f_o learns the learning operator f_i. f_i is learning the params in f_params to complete its task.


Learning resources
	https://blog.evjang.com/2019/02/maml-jax.html