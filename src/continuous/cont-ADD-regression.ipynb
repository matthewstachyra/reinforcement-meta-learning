{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State** is (1) gradient and (2) latent space of all layers up to not including output layer, and (3) task identifying information.\n",
    "\n",
    "**Action** is 40x40 flattened vector of weights between -1 and 1\n",
    "\n",
    "**Reward** is a difference measure (e.g., frobenius norm) between action and trained layer after 10 gradient steps.\n",
    "\n",
    "Episodes are 3 steps long (or whatever the number of hidden layers is)\n",
    "\n",
    "Imp'l details\n",
    "- copy layers\n",
    "- add xavier initialized new layer\n",
    "- run backprop for 10 gradient steps on copied layers + new layer\n",
    "- get distance between the added layer and the layer output by outer network\n",
    "- use that as reward\n",
    "\n",
    "Less complex than discrete\n",
    "- no need for layer pool\n",
    "- no need for task enum\n",
    "- no need for error conditions and complex action logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy \n",
    "import random\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import gymnasium\n",
    "from typing import (\n",
    "    Type,\n",
    "    List,\n",
    "    Tuple,\n",
    ")\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3 import PPO, A2C\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science','ieee', 'notebook', 'bright'])\n",
    "plt.rcParams.update({'figure.dpi': '75'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 41,\n",
       " 'device': 'cuda',\n",
       " 'n_runs': 1,\n",
       " 'epochs': 5,\n",
       " 'timesteps': 1000,\n",
       " 'n_x': 100,\n",
       " 'n_tasks': 2,\n",
       " 'task_min_loss': defaultdict(<function __main__.<lambda>()>, {}),\n",
       " 'task_max_loss': defaultdict(<function __main__.<lambda>()>, {}),\n",
       " 'in_features': 1,\n",
       " 'out_features': 1,\n",
       " 'n_pool_hidden_layers': 6,\n",
       " 'n_hidden_layers_per_network': 3,\n",
       " 'n_layers_per_network': 5,\n",
       " 'n_nodes_per_layer': 40,\n",
       " 'pool_layer_type': torch.nn.modules.linear.Linear,\n",
       " 'batch_size': 32,\n",
       " 'learning_rate': 0.005,\n",
       " 'discount_factor': 0.95,\n",
       " 'action_cache_size': 5,\n",
       " 'num_workers': 0,\n",
       " 'loss_fn': MSELoss(),\n",
       " 'sb3_model': 'RecurrentPPO',\n",
       " 'sb3_policy': 'MlpLstmPolicy',\n",
       " 'log_dir': 'wandb'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_config = {\n",
    "    'seed' : 41,\n",
    "    'device' : 'cuda',\n",
    "    'n_runs' : 1,\n",
    "    'epochs' : 5,\n",
    "    'timesteps' : 1000,\n",
    "    'n_x' : 100,\n",
    "    'n_tasks' : 2,\n",
    "    'task_min_loss' : defaultdict(lambda: None),\n",
    "    'task_max_loss' : defaultdict(lambda: None),\n",
    "    'in_features' : 1,\n",
    "    'out_features' : 1,\n",
    "    'n_pool_hidden_layers' : 10,\n",
    "    'n_hidden_layers_per_network' : 3,\n",
    "    'n_layers_per_network' : 5,\n",
    "    'n_nodes_per_layer' : 40,\n",
    "    'pool_layer_type' : torch.nn.Linear,\n",
    "    'batch_size' : 32,\n",
    "    'learning_rate' : 0.005,\n",
    "    'discount_factor' : 0.95,\n",
    "    'action_cache_size' : 5,\n",
    "    'num_workers' : 0,\n",
    "    'loss_fn' : torch.nn.MSELoss(),\n",
    "    'sb3_model' : 'RecurrentPPO',\n",
    "    'sb3_policy' : 'MlpLstmPolicy',\n",
    "    'log_dir' : 'wandb',\n",
    "    }\n",
    "config = default_config\n",
    "config['n_pool_hidden_layers'] = config['n_tasks'] * config['n_hidden_layers_per_network']\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wandb\u001b[39m.\u001b[39;49minit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     project\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreinforcement-meta-learning\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1193\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[39massert\u001b[39;00m logger\n\u001b[0;32m   1192\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39minterrupted\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n\u001b[1;32m-> 1193\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m   1194\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1195\u001b[0m     error_seen \u001b[39m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     wi \u001b[39m=\u001b[39m _WandbInit()\n\u001b[1;32m-> 1166\u001b[0m     wi\u001b[39m.\u001b[39;49msetup(kwargs)\n\u001b[0;32m   1167\u001b[0m     \u001b[39massert\u001b[39;00m wi\u001b[39m.\u001b[39msettings\n\u001b[0;32m   1168\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:308\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m     settings\u001b[39m.\u001b[39mupdate(init_settings, source\u001b[39m=\u001b[39mSource\u001b[39m.\u001b[39mINIT)\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m settings\u001b[39m.\u001b[39m_offline \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m settings\u001b[39m.\u001b[39m_noop:\n\u001b[1;32m--> 308\u001b[0m     wandb_login\u001b[39m.\u001b[39;49m_login(\n\u001b[0;32m    309\u001b[0m         anonymous\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39manonymous\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    310\u001b[0m         force\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mforce\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    311\u001b[0m         _disable_warning\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    312\u001b[0m         _silent\u001b[39m=\u001b[39;49msettings\u001b[39m.\u001b[39;49mquiet \u001b[39mor\u001b[39;49;00m settings\u001b[39m.\u001b[39;49msilent,\n\u001b[0;32m    313\u001b[0m         _entity\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mentity\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mor\u001b[39;49;00m settings\u001b[39m.\u001b[39;49mentity,\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    316\u001b[0m \u001b[39m# apply updated global state after login was handled\u001b[39;00m\n\u001b[0;32m    317\u001b[0m settings\u001b[39m.\u001b[39m_apply_settings(wandb\u001b[39m.\u001b[39msetup()\u001b[39m.\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:288\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m# perform a login\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m logged_in \u001b[39m=\u001b[39m wlogin\u001b[39m.\u001b[39;49mlogin()\n\u001b[0;32m    290\u001b[0m key \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    291\u001b[0m \u001b[39mif\u001b[39;00m key:\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:140\u001b[0m, in \u001b[0;36m_WandbLogin.login\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_silent:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogin_display()\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m apikey_configured\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:145\u001b[0m, in \u001b[0;36m_WandbLogin.login_display\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlogin_display\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 145\u001b[0m     username \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wl\u001b[39m.\u001b[39;49m_get_username()\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m username:\n\u001b[0;32m    148\u001b[0m         \u001b[39m# check to see if we got an entity from the setup call or from the user\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         entity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_entity \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl\u001b[39m.\u001b[39m_get_entity()\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:194\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._get_username\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_server \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_viewer()\n\u001b[0;32m    195\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_server \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    196\u001b[0m username \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_server\u001b[39m.\u001b[39m_viewer\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39musername\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:216\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._load_viewer\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    214\u001b[0m     settings \u001b[39m=\u001b[39m wandb_settings\u001b[39m.\u001b[39mSettings(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39msettings)\n\u001b[0;32m    215\u001b[0m s \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39mServer(settings\u001b[39m=\u001b[39msettings)\n\u001b[1;32m--> 216\u001b[0m s\u001b[39m.\u001b[39;49mquery_with_timeout()\n\u001b[0;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_server \u001b[39m=\u001b[39m s\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\sdk\\lib\\server.py:35\u001b[0m, in \u001b[0;36mServer.query_with_timeout\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     33\u001b[0m async_viewer \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39masync_call(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39mviewer_server_info, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     viewer_tuple, viewer_thread \u001b[39m=\u001b[39m async_viewer()\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[39m# TODO: currently a bare exception as lots can happen, we should classify\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_network \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\wandb\\util.py:1187\u001b[0m, in \u001b[0;36masync_call.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1185\u001b[0m thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m   1186\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1187\u001b[0m     result \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39;49mget(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mException\u001b[39;00m):\n\u001b[0;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m result\u001b[39m.\u001b[39mwith_traceback(sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='reinforcement-meta-learning',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression\n",
    "sinusoidal curve regression as in MAML 2018 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tasks created.\n"
     ]
    }
   ],
   "source": [
    "lower_bound = torch.tensor(-5).float()\n",
    "upper_bound = torch.tensor(5).float()\n",
    "X = np.linspace(lower_bound, upper_bound, config['n_x'])\n",
    "amplitude_range = torch.tensor([0.1, 5.0]).float()\n",
    "phase_range = torch.tensor([0, math.pi]).float()\n",
    "amps = torch.from_numpy(np.linspace(amplitude_range[0], amplitude_range[1], config['n_tasks'])).float()\n",
    "phases = torch.from_numpy(np.linspace(phase_range[0], phase_range[1], config['n_tasks'])).float()\n",
    "tasks_data = torch.tensor(np.array([ \n",
    "        X\n",
    "        for _ in range(config['n_tasks'])\n",
    "        ])).float()\n",
    "tasks_targets = torch.tensor(np.array([\n",
    "        [((a * np.sin(x)) + p).float()\n",
    "        for x in X] \n",
    "        for a, p in zip(amps, phases)\n",
    "        ])).float()\n",
    "tasks_info = [\n",
    "        {'i' : i, \n",
    "         'amp' : a, \n",
    "         'phase_shift' : p, \n",
    "         'lower_bound' : lower_bound, \n",
    "         'upper_bound' : upper_bound, \n",
    "         'amplitude_range_lower_bound' : amplitude_range[0], \n",
    "         'amplitude_range_upper_bound' : amplitude_range[1], \n",
    "         'phase_range_lower_bound' : phase_range[0],\n",
    "         'phase_range_lower_bound' : phase_range[1]}\n",
    "        for i, (a, p) in enumerate(zip(amps, phases))\n",
    "]\n",
    "print(f'[INFO] Tasks created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n",
      "torch.float32\n",
      "torch.Size([2, 100])\n",
      "torch.float32\n",
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(tasks_data.shape)\n",
    "print(tasks_data.dtype)\n",
    "print(tasks_targets.shape)\n",
    "print(tasks_targets.dtype)\n",
    "print(len(tasks_info))\n",
    "print(len(tasks_info[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerNetworkTask(Dataset):\n",
    "    def __init__(self, data, targets, info):\n",
    "        self.data = data \n",
    "        self.targets = targets\n",
    "        self.info = info\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.data) == config['n_x'], '[ERROR] Length should be the same as n_x.'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.data[index].dtype == torch.float32, f'[ERROR] Expected type torch.float32, got type: {self.data[index].dtype}'\n",
    "        assert self.targets[index].dtype == torch.float32, f'[ERROR] Expected type torch.float32, got type: {self.targets[index].dtype}'\n",
    "        sample = {\n",
    "            'x' : self.data[index],\n",
    "            'y' : self.targets[index],\n",
    "            'info' : self.info\n",
    "        }\n",
    "        return sample\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'[INFO] InnerNetworkTask(data={self.data}, targets={self.targets}, info={self.info})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_and_gradients(layers):\n",
    "    num_layers = len(layers)\n",
    "    max_num_hidden_layers = config['n_hidden_layers_per_network']\n",
    "    num_hidden_layers = num_layers - 2\n",
    "    hidden_layers = layers[1:-1]\n",
    "    params = [layer.weight.detach() for layer in hidden_layers]\n",
    "    gradients = [layer.weight.grad for layer in hidden_layers]\n",
    "    print(f\"params={params}\")\n",
    "    print(f\"gradients={gradients}\")\n",
    "    if num_hidden_layers < config['n_hidden_layers_per_network']:\n",
    "        zero_pad = [torch.zeros((config['n_nodes_per_layer'], config['n_nodes_per_layer']), dtype=torch.float32)] * (max_num_hidden_layers - num_hidden_layers)\n",
    "        zero_pad_tensor = torch.stack(zero_pad)\n",
    "        if len(params) > 0 and len(gradients) > 0:\n",
    "            params = torch.stack(params)\n",
    "            gradients = torch.stack(gradients)\n",
    "            params = torch.cat((params, zero_pad_tensor))\n",
    "            gradients = torch.cat((gradients, zero_pad_tensor)) \n",
    "        else:\n",
    "            params = zero_pad_tensor\n",
    "            gradients = zero_pad_tensor\n",
    "    else:\n",
    "        params = torch.stack(params)\n",
    "        gradients = torch.stack(gradients)\n",
    "    assert params.shape==(max_num_hidden_layers, config['n_nodes_per_layer'], config['n_nodes_per_layer']), f\"[ERROR] Expected params shape={max_num_hidden_layers, config['n_nodes_per_layer'], config['n_nodes_per_layer']}, got {params.shape}\"\n",
    "    return params.view(-1), gradients.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_space(latent_space):\n",
    "    flattened_latent_space = latent_space.view(-1)\n",
    "    flattened_size = flattened_latent_space.numel()\n",
    "    target_size = config['batch_size'] * config['n_nodes_per_layer']\n",
    "    if flattened_size < target_size:\n",
    "        num_elements_to_pad = target_size - flattened_size\n",
    "        padding_tensor = torch.zeros(num_elements_to_pad)\n",
    "        padded_tensor = torch.cat((flattened_latent_space, padding_tensor), dim=0)\n",
    "        return padded_tensor\n",
    "    else:\n",
    "        return flattened_latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0410, -0.3752,  0.1118,  0.2187,  0.0067, -0.2719, -0.0175, -0.3764,\n",
       "         -0.2253,  0.2170, -0.0541, -0.1308, -0.1774, -0.1855,  0.2761, -0.0888,\n",
       "         -0.0083, -0.0719, -0.2583,  0.2767,  0.3335,  0.1720, -0.2971, -0.0023,\n",
       "         -0.0924,  0.0788, -0.3637,  0.1864,  0.0997, -0.1589, -0.1311,  0.1385,\n",
       "         -0.2885, -0.2729,  0.0217, -0.2103,  0.0122,  0.1817,  0.2181,  0.1428]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_input_layer = torch.nn.Linear(in_features=config['in_features'], out_features=config['n_nodes_per_layer'])\n",
    "initial_output_layer = torch.nn.Linear(in_features=config['n_nodes_per_layer'], out_features=config['out_features'])\n",
    "torch.nn.init.xavier_uniform_(initial_input_layer.weight)\n",
    "torch.nn.init.xavier_uniform_(initial_output_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerNetwork(gymnasium.Env, torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                task: InnerNetworkTask,\n",
    "                epoch: int=0,\n",
    "                in_features: int=config['in_features'],\n",
    "                out_features: int=config['out_features'],\n",
    "                learning_rate: float=config['learning_rate'],\n",
    "                batch_size: int=config['batch_size'],\n",
    "                action_cache_size: float=config['action_cache_size'],\n",
    "                num_workers: int=config['num_workers'],\n",
    "                shuffle: bool=True,\n",
    "                ):\n",
    "        super(InnerNetwork, self).__init__()\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.task = task\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.action_cache_size = action_cache_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.prev = defaultdict(lambda: None)\n",
    "        self.curr = defaultdict(lambda: None)\n",
    "        self.data_loader = DataLoader(task, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        self.data_iter = iter(self.data_loader)\n",
    "\n",
    "        # TODO is check whether need to min max scale the reward \n",
    "        \n",
    "        self.initial_input_layer = copy.deepcopy(initial_input_layer)\n",
    "        self.initial_output_layer = copy.deepcopy(initial_output_layer)\n",
    "        self.layers = torch.nn.ModuleList([self.initial_input_layer, self.initial_output_layer]) \n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.opt = torch.optim.Adam(self.layers.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        self.timestep = 0\n",
    "        self.loss_vals = []\n",
    "        self.reward_vals = []\n",
    "        self.train()\n",
    "        self.next_batch()\n",
    "        self.run()\n",
    "        self.observation_space = gymnasium.spaces.box.Box(low=float('-inf'), high=float('inf'), shape=self.build_state().shape)\n",
    "        self.action_space = gymnasium.spaces.box.Box(low=-1, high=1, shape=(config['n_nodes_per_layer'] * config['n_nodes_per_layer'], ))\n",
    "\n",
    "    def step(self, action: np.int64) -> Tuple[torch.Tensor, float, bool, dict]: \n",
    "        self.timestep += 1\n",
    "        self.next_batch()\n",
    "\n",
    "        # update inner network\n",
    "        new_hidden_layer = torch.nn.Linear(config['n_nodes_per_layer'], config['n_nodes_per_layer'])\n",
    "        weights = torch.tensor(action).reshape(config['n_nodes_per_layer'], config['n_nodes_per_layer'])\n",
    "        new_hidden_layer.weight.data = weights\n",
    "        output_layer = self.layers.pop(-1) \n",
    "        self.layers.append(new_hidden_layer)\n",
    "        self.layers.append(output_layer)\n",
    "        termination = True if len(self.layers)==config['n_layers_per_network'] else False\n",
    "\n",
    "        self.run()\n",
    "        s_prime = self.build_state()\n",
    "        reward = self.reward(action)\n",
    "        self.log()\n",
    "\n",
    "        return (\n",
    "            s_prime,\n",
    "            reward, \n",
    "            termination,\n",
    "            False,\n",
    "            {}\n",
    "        )\n",
    "            \n",
    "    def next_batch(self, throw_exception=False) -> None:\n",
    "        self.prev = self.curr\n",
    "        self.curr = defaultdict(lambda: None)\n",
    "\n",
    "        if (throw_exception):\n",
    "            batch = next(self.data_iter)\n",
    "            self.curr['x'] = batch['x'].view(-1, 1)\n",
    "            self.curr['y'] = batch['y'].view(-1, 1)\n",
    "            self.curr['info'] = batch['info']\n",
    "        else: \n",
    "            try:\n",
    "                batch = next(self.data_iter)\n",
    "            except StopIteration:\n",
    "                self.data_loader = DataLoader(self.task, batch_size=self.batch_size, shuffle=self.shuffle, num_workers=self.num_workers)\n",
    "                self.data_iter = iter(self.data_loader)\n",
    "                batch = next(self.data_iter)\n",
    "            finally:\n",
    "                self.curr['x'] = batch['x'].view(-1 ,1)\n",
    "                self.curr['y'] = batch['y'].view(-1, 1)\n",
    "                self.curr['info'] = batch['info']\n",
    "    \n",
    "    def run(self) -> None: \n",
    "        if self.training:\n",
    "            self.opt = torch.optim.Adam(self.layers.parameters(), lr=self.learning_rate) \n",
    "            self.opt.zero_grad()\n",
    "            self.forward(self.curr['x'])\n",
    "            loss = self.curr['loss']\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "        else:\n",
    "            self.forward(self.curr['x'])\n",
    "\n",
    "    def forward(self, x) -> torch.tensor:\n",
    "        print(f\"forward(): {self.layers}\")\n",
    "        for i in range(len(self.layers) - 1): \n",
    "            x = torch.nn.functional.relu(self.layers[i](x))\n",
    "        self.curr['latent_space'] = x\n",
    "        self.curr['y_hat'] = self.layers[-1](x) \n",
    "        y = self.curr['y']\n",
    "        self.curr['loss'] = copy.copy(self.loss_fn(y, self.curr['y_hat']))\n",
    "        print(f\"loss={self.curr['loss']}\")\n",
    "        return self.curr['y_hat']\n",
    "    \n",
    "    def build_state(self) -> np.ndarray:\n",
    "        task_info = torch.tensor([self.task.info['amp'], self.task.info['phase_shift']]).squeeze()\n",
    "        loss = torch.Tensor([self.curr['loss']])\n",
    "        yhat_scale = torch.Tensor([torch.Tensor(torch.max(torch.abs(self.curr['y_hat']))).detach().item()])\n",
    "        latent_space = get_latent_space(self.curr['latent_space'])\n",
    "        params, gradients = get_params_and_gradients(self.layers)\n",
    "        \n",
    "        return torch.concat((\n",
    "            task_info,\n",
    "            loss,\n",
    "            yhat_scale,\n",
    "            latent_space,\n",
    "            gradients,\n",
    "            # params,\n",
    "        ), dim=0).detach().numpy()\n",
    "    \n",
    "    def reward(self, action) -> torch.Tensor:\n",
    "        # create dummy layer\n",
    "        dummy_layer = torch.nn.Linear(in_features=config['n_nodes_per_layer'], out_features=config['n_nodes_per_layer'])\n",
    "        torch.nn.init.xavier_uniform_(dummy_layer.weight)\n",
    "        # copy layers and add dummy layer\n",
    "        layers_copy = copy.deepcopy(self.layers)\n",
    "        output_layer = layers_copy.pop(-1) \n",
    "        layers_copy.append(dummy_layer)\n",
    "        layers_copy.append(output_layer)\n",
    "        # create separate optimizer for these layers\n",
    "        opt = torch.optim.Adam(layers_copy.parameters(), lr=self.learning_rate) \n",
    "        # train copy network 10 gradient steps\n",
    "        for _ in range(10):\n",
    "            self.next_batch()\n",
    "            x = self.curr['x']\n",
    "            for i in range(len(layers_copy) - 1): \n",
    "                x = torch.nn.functional.relu(layers_copy[i](x))\n",
    "            yhats = layers_copy[-1](x) \n",
    "            loss = self.loss_fn(self.curr['y'], yhats)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # get distance between weight of dummy layer and action from outer network\n",
    "        trained_dummy_layer = layers_copy[-2]\n",
    "        # TODO is to try different difference/distance measures\n",
    "        distance = torch.norm(trained_dummy_layer.weight.detach() - torch.tensor(action).reshape(config['n_nodes_per_layer'], config['n_nodes_per_layer']), p='fro')\n",
    "        # negative distance is the reward (because we want the layers to be more similar)\n",
    "        reward = -distance\n",
    "        self.curr['reward'] = reward\n",
    "        return reward\n",
    "\n",
    "    def log(self):\n",
    "        print(f\"loss from within log()={self.curr['loss']}\")\n",
    "        task_num = str(self.task.info['i'])\n",
    "        self.loss_vals.append(copy.copy(self.curr['loss']))\n",
    "        self.reward_vals.append(copy.copy(self.curr['reward']))\n",
    "        wandb.log({ f'loss_task{task_num}_per_step' : self.curr['loss']})\n",
    "        wandb.log({ f'reward_task{task_num}_per_step' : self.curr['reward']})\n",
    "\n",
    "    def reset(self, seed=None) -> np.ndarray:\n",
    "        print(f'[INFO] Reset at {self.timestep}')\n",
    "        self.timestep = 0\n",
    "        self.prev = defaultdict(lambda: None)\n",
    "        self.curr = defaultdict(lambda: None)\n",
    "        self.initial_input_layer = copy.deepcopy(initial_input_layer)\n",
    "        self.initial_output_layer = copy.deepcopy(initial_output_layer)\n",
    "        self.layers = torch.nn.ModuleList([self.initial_input_layer, self.initial_output_layer]) \n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.opt = torch.optim.Adam(self.layers.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # TODO is to figure out what to do with loss_vals and reward_vals if keeping this architecture\n",
    "        self.loss_vals = []\n",
    "        self.reward_vals = []\n",
    "\n",
    "        self.train()\n",
    "        self.next_batch()\n",
    "        self.run()\n",
    "        return self.build_state(), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REML:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tasks: List[InnerNetworkTask],\n",
    "        model=config['sb3_model'],\n",
    "        policy=config['sb3_policy'],\n",
    "        epochs: int=config['epochs'],\n",
    "        timesteps: int=config['timesteps'],\n",
    "        device: str=config['device'],\n",
    "        log_dir: str=f\"./{config['log_dir']}/{config['sb3_model']}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        ):\n",
    "        self.tasks = tasks\n",
    "        if config['sb3_model']=='PPO':\n",
    "            model = PPO\n",
    "        elif config['sb3_model']=='RecurrentPPO':\n",
    "            model = RecurrentPPO\n",
    "        elif config['sb3_model']=='A2C':\n",
    "            model = A2C\n",
    "        dummy_env = self.make_env(tasks[0])\n",
    "        self.model = model(policy, dummy_env, tensorboard_log=log_dir, n_epochs=5, batch_size=32, n_steps=32)\n",
    "        self.policy = policy\n",
    "        self.epochs = epochs\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device # TODO is to check whether cuda is used as assumed\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f'REML(model={self.model}, policy={self.policy})'\n",
    "    \n",
    "    def make_env(self, task, epoch=None) -> gymnasium.Env:\n",
    "        return gymnasium.wrappers.NormalizeObservation(InnerNetwork(task, epoch=epoch))\n",
    "\n",
    "    def train(self):\n",
    "        # wraps stablebaselines learn() so we call it n * m times\n",
    "        # n is the number of epochs where we run all m tasks\n",
    "        # we use the same policy, swapping out envs for the n tasks, m times. \n",
    "\n",
    "        # to calculate variance\n",
    "        # e.g., task: [ n: [epoch: [100 values]] ] / array with n rows, epoch columns \n",
    "        # where cell @ [nth run][mth epoch] is cumulative loss/reward\n",
    "        return_taskkey_epochcol = defaultdict(lambda: [])\n",
    "        cumuloss_taskkey_epochcol = defaultdict(lambda: [])\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'[INFO] Epoch={epoch + 1}/{self.epochs}')\n",
    "            for i, task in enumerate(self.tasks): \n",
    "                self.task = task\n",
    "                print(f'[INFO] Task={i+1}/{len(self.tasks)}')\n",
    "\n",
    "                # each task gets its own network\n",
    "                self.env = self.make_env(self.task, epoch=epoch)\n",
    "                self.model.set_env(self.env)\n",
    "                self.model.learn(total_timesteps=self.timesteps)\n",
    "\n",
    "                # track reward and loss for plots\n",
    "                return_taskkey_epochcol[str(self.task.info['i'])].append(sum(self.env.reward_vals))\n",
    "                cumuloss_taskkey_epochcol[str(self.task.info['i'])].append(sum(self.env.loss_vals))\n",
    "\n",
    "                # log to wandb\n",
    "                wandb.log({ f'cumulative_reward_task{i}_per_epoch' : sum(self.env.reward_vals) })\n",
    "                wandb.log({ f'cumulative_loss_task{i}_per_epoch' : sum(self.env.loss_vals) })\n",
    "\n",
    "                # sine curves\n",
    "                self.generate_sine_curve(epoch=epoch, task=i, image=True, title='training_sine_curves', args={'label' : f'task_{i}'})\n",
    "                plt.plot(self.task.data, self.task.targets, linestyle='--', label='ground truth')\n",
    "    \n",
    "    def evaluate_convergence_speed(self, steps=100) -> dict:\n",
    "        # generates loss curve over 'steps' per task\n",
    "        # TODO is to add option to do so with std if n_runs>1\n",
    "\n",
    "        lossperstep_bytask = defaultdict(lambda: [])\n",
    "\n",
    "        for task in self.tasks: \n",
    "            env = self.make_env(task)\n",
    "            self.model.set_env(env, force_reset=False)\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "            while len(env.layers) < config['n_layers_per_network']:\n",
    "                action, _ = self.model.predict(obs)\n",
    "                obs, _, _, _, _ = env.step(action)\n",
    "\n",
    "            for _ in range(steps):\n",
    "                action, _ = self.model.predict(obs)\n",
    "                obs, _, _, _, _ = env.step(action)\n",
    "                lossperstep_bytask[task].append(env.curr['loss'])\n",
    "\n",
    "        return lossperstep_bytask\n",
    "\n",
    "    def generate_sine_curve(self, env=None, data=None, epoch=None, task=None, image=False, new_figures=False, title=None, args=defaultdict()) -> List:\n",
    "        # generates sine curve after 'env.layers' is full, with option to set env, limit to \n",
    "        # subset of env data (for few shot evaluation), and to create png\n",
    "\n",
    "        if env is not None:\n",
    "            self.env = env\n",
    "            self.model.set_env(env, force_reset=False)\n",
    "\n",
    "        self.env.eval()\n",
    "        obs, _ = self.env.reset()\n",
    "        \n",
    "        while len(self.env.layers)!=config['n_layers_per_network']:\n",
    "            action, _ = self.model.predict(obs)\n",
    "            obs, _, _, _, _ = self.env.step(action)\n",
    "        \n",
    "        # if data is specified, wrap in new task\n",
    "        # if data is not specified, the iterator is used over set\n",
    "        if data is not None:\n",
    "            dataset = InnerNetworkTask(data=data[:, 0].clone(), targets=data[:, 1].clone(), info=self.task.info)\n",
    "        else: \n",
    "            dataset = self.task\n",
    "\n",
    "        xs, ys = dataset.data.clone(), dataset.targets.clone()\n",
    "        xs, ys = xs.view(len(xs), 1), ys.view(len(ys), 1)\n",
    "        for i in range(len(self.env.layers) - 1): \n",
    "            xs = torch.nn.functional.relu(self.env.layers[i](xs))\n",
    "        yhats = self.env.layers[-1](xs) \n",
    "\n",
    "        if new_figures:\n",
    "            plt.figure()\n",
    "        plot_title = title if title!=None else f'sine_curve_epoch_{epoch}_task_{task}' if epoch!=None and task!=None else 'sine_curve'\n",
    "        plot_path = f'{self.log_dir}/{plot_title}.png'  \n",
    "        plt.plot(dataset.data, [yhat.detach().numpy() for yhat in yhats], **args)\n",
    "        plt.plot(dataset.data, dataset.targets, label='ground truth', linestyle='--')\n",
    "        plt.title(plot_title)\n",
    "        plt.legend()\n",
    "\n",
    "        if image:\n",
    "            plt.savefig(plot_path)\n",
    "            wandb.log({plot_title: wandb.Image(plot_path)})\n",
    "       \n",
    "        xs, yhats = dataset.data, [yhat.detach().numpy() for yhat in yhats]\n",
    "        return xs, yhats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward(): ModuleList(\n",
      "  (0): Linear(in_features=1, out_features=40, bias=True)\n",
      "  (1): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "loss=27.368581771850586\n"
     ]
    }
   ],
   "source": [
    "tasks = [InnerNetworkTask(data=tasks_data[i], targets=tasks_targets[i], info=tasks_info[i]) for i in range(config['n_tasks'])]\n",
    "eval_task = random.choice(list(tasks))\n",
    "training_tasks = list(set(tasks) - {eval_task})\n",
    "reml = REML(tasks=training_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] n=1\n",
      "[INFO] Epoch=1/5\n",
      "[INFO] Task=1/1\n",
      "forward(): ModuleList(\n",
      "  (0): Linear(in_features=1, out_features=40, bias=True)\n",
      "  (1): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "loss=26.467178344726562\n",
      "[INFO] Reset at 0\n",
      "forward(): ModuleList(\n",
      "  (0): Linear(in_features=1, out_features=40, bias=True)\n",
      "  (1): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "loss=27.304424285888672\n",
      "forward(): ModuleList(\n",
      "  (0): Linear(in_features=1, out_features=40, bias=True)\n",
      "  (1): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (2): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "loss=52.905555725097656\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mn_runs\u001b[39m\u001b[39m'\u001b[39m]): \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO] n=\u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     return_taskkey_epochvalues, cumuloss_taskkey_epochvalues \u001b[39m=\u001b[39m reml\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         return_taskkey_nrow_epochcol[\u001b[39mstr\u001b[39m(task\u001b[39m.\u001b[39minfo[\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mappend(return_taskkey_epochvalues[\u001b[39mstr\u001b[39m(task\u001b[39m.\u001b[39minfo[\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m])])\n",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_env(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask, epoch\u001b[39m=\u001b[39mepoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_env(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimesteps)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# track reward and loss for plots\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m return_taskkey_epochcol[\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39minfo[\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mappend(\u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreward_vals))\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:469\u001b[0m, in \u001b[0;36mRecurrentPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    466\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    468\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 469\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    471\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    472\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:254\u001b[0m, in \u001b[0;36mRecurrentPPO.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, spaces\u001b[39m.\u001b[39mBox):\n\u001b[0;32m    252\u001b[0m     clipped_actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mlow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mhigh)\n\u001b[1;32m--> 254\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(clipped_actions)\n\u001b[0;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[0;32m    258\u001b[0m \u001b[39m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\stach\\miniconda3\\envs\\masters-thesis\\lib\\site-packages\\gymnasium\\wrappers\\normalize.py:76\u001b[0m, in \u001b[0;36mNormalizeObservation.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and normalizes the observation.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     obs, rews, terminateds, truncateds, infos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_vector_env:\n\u001b[0;32m     78\u001b[0m         obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(obs)\n",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m termination \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)\u001b[39m==\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mn_layers_per_network\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m s_prime \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_state()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog()\n",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m yhat_scale \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([torch\u001b[39m.\u001b[39mTensor(torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr[\u001b[39m'\u001b[39m\u001b[39my_hat\u001b[39m\u001b[39m'\u001b[39m])))\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem()])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m latent_space \u001b[39m=\u001b[39m get_latent_space(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr[\u001b[39m'\u001b[39m\u001b[39mlatent_space\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m params, gradients \u001b[39m=\u001b[39m get_params_and_gradients(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mconcat((\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     task_info,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     loss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     \u001b[39m# params,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m ), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;32mc:\\Users\\stach\\Documents\\masters-thesis\\src\\continuous\\cont-ADD-regression.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(params) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(gradients) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(params)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     gradients \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(gradients)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((params, zero_pad_tensor))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stach/Documents/masters-thesis/src/continuous/cont-ADD-regression.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     gradients \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((gradients, zero_pad_tensor)) \n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got NoneType"
     ]
    }
   ],
   "source": [
    "path = f\"meta_{config['sb3_model']}_{datetime.datetime.now().strftime('%H-%M')}\"\n",
    "return_taskkey_nrow_epochcol = defaultdict(lambda: [])\n",
    "cumuloss_taskkey_nrow_epochcol = defaultdict(lambda: [])\n",
    "\n",
    "#        epoch1  epoch2  epoch3 ... <- epochs as cols\n",
    "# task: [return, return, return, ...] \n",
    "# task: [cumulative loss, cumulative loss, cumulative loss, ...] \n",
    "for n in range(config['n_runs']): \n",
    "    print(f\"[INFO] n={n+1}\")\n",
    "    return_taskkey_epochvalues, cumuloss_taskkey_epochvalues = reml.train()\n",
    "    for task in tasks:\n",
    "        return_taskkey_nrow_epochcol[str(task.info['i'])].append(return_taskkey_epochvalues[str(task.info['i'])])\n",
    "        cumuloss_taskkey_nrow_epochcol[str(task.info['i'])].append(cumuloss_taskkey_epochvalues[str(task.info['i'])])\n",
    "\n",
    "# save to json\n",
    "with open(f'returns_{path}', 'w') as json_file:\n",
    "    json.dump(return_taskkey_nrow_epochcol, json_file, indent=4)\n",
    "with open(f'cumuloss_{path}', 'w') as json_file:\n",
    "    json.dump(cumuloss_taskkey_nrow_epochcol, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speed of training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loss for meta trained network per step\n",
    "reml = REML(layer_pool=pool, tasks=tasks)\n",
    "reml.model.load(path)\n",
    "meta_lossperstep_bytask = reml.evaluate_loss_curves()\n",
    "\n",
    "# get loss for vanilla network per step\n",
    "vanilla_lossperstep_bytask = {}\n",
    "for task, x, y in zip(tasks, tasks_data, tasks_targets):\n",
    "    model = RegressionModel()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    vanilla_lossperstep_bytask[task] = []\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(x.view(-1, 1))\n",
    "        loss = criterion(outputs, y.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        vanilla_lossperstep_bytask[task].append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(tasks_data, tasks_targets)):\n",
    "    task = tasks[i]\n",
    "    vanilla_label = f'Vanilla network: Task {i+1}' \n",
    "    meta_label = f'Meta-trained network: Task {i+1}' \n",
    "    meta_loss_vals = [val.detach().numpy() for val in meta_lossperstep_bytask[task]]\n",
    "    vanilla_loss_vals = [val.detach().numpy() for val in vanilla_lossperstep_bytask[task]]\n",
    "    plt.plot(range(100), vanilla_loss_vals, label=vanilla_label)\n",
    "    plt.plot(range(100), meta_loss_vals, label=meta_label)\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### few shot learning tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unseen task\n",
    "# choose 5 and 10 datapoints on it, K = 5, K = 10\n",
    "k = 5\n",
    "k_pairs = torch.tensor(random.sample(list(zip(eval_task.data, eval_task.targets)), k))\n",
    "print(len(k_pairs))\n",
    "print(k_pairs)\n",
    "\n",
    "# network still recieves the same 100 x values {-5, ..., 5}\n",
    "# the difference is that a target value is only provided for 5 or 10 of these 100 values\n",
    "# start by generating the 'pre-update' curve \n",
    "# next pass k datapoints and do 1 gradient update step to get the curve\n",
    "# next do 9 more gradient update steps (total 10) to get next curve\n",
    "# plot 'pre-update', '1 grad step', '10 grad steps' curves together with the 'k_pairs' data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env with eval task\n",
    "reml = REML(layer_pool=pool, tasks=tasks)\n",
    "reml.model.load(path)\n",
    "env = reml.make_env(eval_task, pool)\n",
    "reml.model.set_env(env)\n",
    "reml.env = env\n",
    "reml.task = eval_task\n",
    "\n",
    "# ground truth\n",
    "plt.plot(eval_task.data, eval_task.targets, linestyle='--', label='ground truth')\n",
    "\n",
    "# pre-update\n",
    "reml.generate_sine_curve(env=env, args={'linestyle' : '--', 'label': 'pre-update'})\n",
    "\n",
    "# k points \n",
    "plt.scatter(k_pairs[:, 0], k_pairs[:, 1], marker='^', color='b', label='k points')\n",
    "\n",
    "# train for 1 grad step\n",
    "reml.env.batch_size = k\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(1):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' :'1 grad step'})\n",
    "    \n",
    "# train for 10 grad steps\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(10):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' : '10 grad steps'})\n",
    "plt.title('REML, k=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "k_pairs = torch.tensor(random.sample(list(zip(eval_task.data, eval_task.targets)), k))\n",
    "print(len(k_pairs))\n",
    "print(k_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reml = REML(layer_pool=pool, tasks=tasks)\n",
    "reml.model.load(path)\n",
    "env = reml.make_env(eval_task)\n",
    "reml.model.set_env(env)\n",
    "reml.env = env\n",
    "reml.task = eval_task\n",
    "\n",
    "# ground truth\n",
    "plt.plot(eval_task.data, eval_task.targets, linestyle='--', label='ground truth')\n",
    "\n",
    "# pre-update\n",
    "reml.generate_sine_curve(env=env, args={'linestyle' : '--', 'label': 'pre-update'})\n",
    "\n",
    "# k points \n",
    "plt.scatter(k_pairs[:, 0], k_pairs[:, 1], marker='^', color='b', label='k points')\n",
    "\n",
    "# train for 1 grad step\n",
    "reml.env.batch_size = k\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(1):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' :'1 grad step'})\n",
    "    \n",
    "# train for 10 grad steps\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(10):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' : '10 grad steps'})\n",
    "plt.title('REML, k=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## episodic learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['episodic'] = True\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [InnerNetworkTask(data=tasks_data[i], targets=tasks_targets[i], info=tasks_info[i]) for i in range(config['n_tasks'])]\n",
    "eval_task = random.choice(list(tasks))\n",
    "training_tasks = list(set(tasks) - {eval_task})\n",
    "pool = LayerPool(layers=layers) if config['pretrain'] else LayerPool(layers=None)\n",
    "reml = REML(layer_pool=pool, tasks=training_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reml.train()\n",
    "path = f\"meta_episodic_{config['sb3_model']}_{datetime.datetime.now().strftime('%H-%M')}\"\n",
    "reml.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loss for meta trained network per step\n",
    "reml = REML(layer_pool=pool, tasks=tasks)\n",
    "reml.model.load(path)\n",
    "meta_lossperstep_bytask = reml.evaluate_loss_curves()\n",
    "\n",
    "# get loss for vanilla network per step\n",
    "vanilla_lossperstep_bytask = {}\n",
    "for task, x, y in zip(tasks, tasks_data, tasks_targets):\n",
    "    model = RegressionModel()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    model.train()\n",
    "    vanilla_lossperstep_bytask[task] = []\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(x.view(-1, 1))\n",
    "        loss = criterion(outputs, y.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        vanilla_lossperstep_bytask[task].append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(tasks_data, tasks_targets)):\n",
    "    task = tasks[i]\n",
    "    vanilla_label = f'Vanilla network: Task {i+1}' \n",
    "    meta_label = f'Meta-trained network: Task {i+1}' \n",
    "    meta_loss_vals = [val.detach().numpy() for val in meta_lossperstep_bytask[task]]\n",
    "    vanilla_loss_vals = [val.detach().numpy() for val in vanilla_lossperstep_bytask[task]]\n",
    "    plt.plot(range(100), vanilla_loss_vals, label=vanilla_label)\n",
    "    plt.plot(range(100), meta_loss_vals, label=meta_label)\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "k_pairs = torch.tensor(random.sample(list(zip(eval_task.data, eval_task.targets)), k))\n",
    "print(len(k_pairs))\n",
    "print(k_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env with eval task\n",
    "reml = REML(layer_pool=pool, tasks=tasks)\n",
    "reml.model.load(path)\n",
    "env = reml.make_env(eval_task, pool)\n",
    "reml.model.set_env(env)\n",
    "reml.env = env\n",
    "reml.task = eval_task\n",
    "\n",
    "# ground truth\n",
    "plt.plot(eval_task.data, eval_task.targets, linestyle='--', label='ground truth')\n",
    "\n",
    "# pre-update\n",
    "reml.generate_sine_curve(env=env, args={'linestyle' : '--', 'label': 'pre-update'})\n",
    "\n",
    "# k points \n",
    "plt.scatter(k_pairs[:, 0], k_pairs[:, 1], marker='^', color='b', label='k points')\n",
    "\n",
    "# train for 1 grad step\n",
    "reml.env.batch_size = k\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(1):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' :'1 grad step'})\n",
    "    \n",
    "# train for 10 grad steps\n",
    "obs, _ = reml.env.reset()\n",
    "for _ in range(10):\n",
    "    action, _ = reml.model.predict(obs)\n",
    "    obs, _, _, _, _ = reml.env.step(action)\n",
    "reml.generate_sine_curve(env=env, args={'label' : '10 grad steps'})\n",
    "plt.title('REML, k=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
