wandb: Appending key for api.wandb.ai to your netrc file: /cluster/home/mstach01/.netrc
2023-12-20 16:53:17.951327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.
wandb: Currently logged in as: mattstachyra. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /cluster/home/mstach01/code/reinforcement-meta-learning/src/discrete/wandb/run-20231220_165334-9x8otrou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-wood-429
wandb: ⭐️ View project at https://wandb.ai/mattstachyra/reinforcement-meta-learning
wandb: 🚀 View run at https://wandb.ai/mattstachyra/reinforcement-meta-learning/runs/9x8otrou
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: | 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   cumulative_loss_run1_task0_per_epoch █▁
wandb:   cumulative_loss_run2_task0_per_epoch ▁█
wandb: cumulative_reward_run1_task0_per_epoch █▁
wandb: cumulative_reward_run2_task0_per_epoch █▁
wandb:            errors_run1_task0_per_epoch █▁
wandb:            errors_run2_task0_per_epoch ▁█
wandb:                    loss_task0_per_step ▁▄▁▁▁▁▅▁▁▄▁▁█▁▁▁▂▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:                    loss_task1_per_step ▇▂▄▇▂█▄▅▆▄▆▅▄▇█▆▆▆▄▄▄▆▄▅▃▅▇▃▇▁▄▅▅█▃▂▄▄▅▃
wandb:                  reward_task0_per_step ▁▁▁▁▁▁▁██▁▁▁▁██▁█▁▁▁██▁█▁▁▁▁█▁▁██▁█▁▁▁██
wandb:                  reward_task1_per_step  ▁▁ ▁▁▁ ▁▁▁▁▁▁▁▁▁▁▁▁   ▁  ▁▁▁ ▁  ▁  ▁▁  
wandb: 
wandb: Run summary:
wandb:   cumulative_loss_run1_task0_per_epoch 0.18197
wandb:   cumulative_loss_run2_task0_per_epoch 0.24533
wandb: cumulative_reward_run1_task0_per_epoch -4.00211
wandb: cumulative_reward_run2_task0_per_epoch -3.02199
wandb:            errors_run1_task0_per_epoch 72
wandb:            errors_run2_task0_per_epoch 73
wandb:                    loss_task0_per_step 0.00496
wandb:                    loss_task1_per_step 14.60376
wandb:                  reward_task0_per_step -0.00143
wandb:                  reward_task1_per_step nan
wandb: 
wandb: 🚀 View run dashing-wood-429 at: https://wandb.ai/mattstachyra/reinforcement-meta-learning/runs/9x8otrou
wandb: ️⚡ View job at https://wandb.ai/mattstachyra/reinforcement-meta-learning/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzY1Nzc3Ng==/version_details/v18
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231220_165334-9x8otrou/logs
