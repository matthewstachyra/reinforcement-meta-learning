\chapter{Method}
\label{Method}
\minitoc 

\section{Preliminaries}
\section{Formulation}
\section{Policy Representation}
\section{Policy Optimization}
\section{Design}
\section{Algorithm}
\section{Implementation}
REML was implemented using Pytorch for the layers and functions comprising the 
inner networks and Stablebaselines3 with its open-source implementations of deep RL 
algorithm for the outer network or meta-policy \cite{pytorch, RafHilGleKanErnDor:21}. 
Stablebaselines3 was developed by researchers with the intent to 
provide reliable baselines given recent findings that deep RL results are hard to 
reproduce. It ws found that the same RL algorithms produce different results depending 
on seed and other minor choices made in the implementation \cite{HenIslBacPinPreMeg:18}. 
In fact, these differences were found to be greater in some cases than the differences between
deep RL algorithms \cite{EngIlySanTsi:20}. Stablebaselines3 benchmarks their implementations
on common environments used in research and compares theirs to other implementations. 
Environments used in thesis are custom and created by the author using Gymnasium \cite{gymnasium}.
\\\\
Computations were carried out using the Tufts University High Performance Cluster (HPC) 
with 1 P100 GPU for batch jobs running about 4 hours for the regression and 12
hours for the classification tasks.
\\\\
Evaluation data was captured and analyzed using Tensorboard and Weights \& Biases (wandb)
\cite{tensorflow2015-whitepaper, wandb}. Plots were generated using matplotlib with 
scienceplots \cite{mmatplotlib SciencePlots}.


